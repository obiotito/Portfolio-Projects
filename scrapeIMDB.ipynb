{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from bs4) (4.9.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1279 sha256=957627c13e942c23a6d331b2b2ad74a9fd48762f8487ab9381e0b99257368870\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\75\\78\\21\\68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model responsibile for scrapping\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# model responsible for get the website and exporting to Excel file\n",
    "import requests, openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Top 250 Rated Movies']\n"
     ]
    }
   ],
   "source": [
    "# Create excel file\n",
    "\n",
    "excel = openpyxl.Workbook()\n",
    "sheet = excel.active    # selects the active sheet\n",
    "sheet.title = 'Top 250 Rated Movies'    # names the sheet\n",
    "sheet.append(['Movie Rank', 'Movie Name', 'Year of Release', 'IMDB Rating'])    # inputs the first line which will be used as header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'source = requests.get' gets the web source code. 'source.raise_for_status()'throws an error if not a valid URL.\n",
    "# Put them in a try-except block prevents the system from crashing due to an error.\n",
    "\n",
    "try:\n",
    "    source = requests.get('https://www.imdb.com/chart/top/')\n",
    "    source.raise_for_status() \n",
    "    \n",
    "    soup = BeautifulSoup(source.text, 'html.parser')    # parses the html source code into beautiful soup\n",
    "    \n",
    "    movies = soup.find('tbody', class_=\"lister-list\").find_all('tr')   # fetches the parent table where the data lays and fetches all rows within \n",
    "    \n",
    "    \n",
    "    # loop to iterate over the list of rows\n",
    "    \n",
    "    for movie in movies:\n",
    "        \n",
    "        name = movie.find('td', class_=\"titleColumn\").a.text    # fetches the text content in the ahref\n",
    "        \n",
    "        rank = movie.find('td', class_=\"titleColumn\").get_text(strip=True).split('.')[0]    #fetches the text content, strips spaces, splits text on \".\" and pick the text in the first index\n",
    "        \n",
    "        year = movie.find('td', class_=\"titleColumn\").span.text.strip('()')    #fetches the text in the span and removes the ()\n",
    "        \n",
    "        rating = movie.find('td', class_=\"ratingColumn imdbRating\").strong.text    # fetches the text from strong\n",
    "        \n",
    "        sheet.append([rank, name, year, rating])    # after every iteration, output is attached to the excel sheet\n",
    "        \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "\n",
    "#  Save as excel file\n",
    "\n",
    "excel.save('IMDB Movie Ratings.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
